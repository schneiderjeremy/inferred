{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20ae6eb-e789-42eb-9900-6b42181d7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "# If you want pyarrow as the backend for parquet (recommended)\n",
    "# pip install pyarrow\n",
    "# and optionally:\n",
    "# pd.set_option(\"io.parquet.engine\", \"pyarrow\")\n",
    "\n",
    "#---------------------------------------\n",
    "# Years\n",
    "#---------------------------------------\n",
    "years = list(range(2016, 2023))\n",
    "base_path = os.path.join(\"..\") \n",
    "#---------------------------------------\n",
    "# Paths (adjust as needed)\n",
    "#---------------------------------------\n",
    "path_comtrade = os.path.join(base_path, \"raw\", \"comtrade\")\n",
    "path_wits     = os.path.join(base_path, \"raw\", \"wits\")\n",
    "path_oecd_tc  = os.path.join(base_path, \"raw\", \"oecd\")\n",
    "path_out      = os.path.join(base_path, \"clean\", \"flows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc475e9b-ab86-4d07-a904-cc97212a0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# Constants / helpers\n",
    "#---------------------------------------\n",
    "toosmall_territories = [\n",
    "    \"Åland Islands \",\"American Samoa\",\"Antarctica\",\"Bonaire\",\"Bouvet Island\",\"Br. Antarctic Terr.\",\n",
    "    \"Br. Indian Ocean Terr.\",\"Br. Virgin Isds\",\"Christmas Isds\",\"Cocos Isds\",\"Cook Isds\",\"Curaçao\",\n",
    "    \"Europe EU, nes\",\"Faeroe Isds\",\"Falkland Isds (Malvinas)\",\"Fr. South Antarctic Terr.\",\"FS Micronesia\",\n",
    "    \"Heard Island and McDonald Islands\",\"French Polynesia\",\"Gibraltar\",\"Guam\",\"Guernsey\",\n",
    "    \"Heard Island and McDonald Islands\",\"Holy See (Vatican City State)\",\"Isle of Man \",\"Jersey\",\"Libya\",\n",
    "    \"Liechtenstein \",\"Marshall Isds\",\"Martinique (Overseas France)\",\"Metropolitan France\",\"Montserrat\",\n",
    "    \"Neutral Zone\",\"New Caledonia\",\"N. Mariana Isds\",\"Norfolk Isds\",\n",
    "    \"Norway, excluding Svalbard and Jan Mayen\",\"Niue\",\"Pitcairn\",\"Puerto Rico \",\n",
    "    \"Saint Barthélemy\",\"Saint Helena\",\"Saint Maarten\",\"Saint Martin (French part) \",\n",
    "    \"Saint Pierre and Miquelon\",\"South Georgia and the South Sandwich Islands\",\n",
    "    \"Svalbard and Jan Mayen Islands \",\"Switzerland \",\"Taiwan, Province of China\",\"Tokelau\",\n",
    "    \"Turks and Caicos Isds\",\"United States Minor Outlying Islands\",\"US Misc. Pacific Isds\",\n",
    "    \"United States of America\",\"Wallis and Futuna Isds\",\"Western Sahara\"\n",
    "]\n",
    "\n",
    "eu_countries = [\n",
    "    \"Austria\",\"Belgium\",\"Bulgaria\",\"Croatia\",\"Cyprus\",\"Czechia\",\"Denmark\",\"Estonia\",\n",
    "    \"Finland\",\"France\",\"Germany\",\"Greece\",\"Hungary\",\"Ireland\",\"Italy\",\"Latvia\",\"Lithuania\",\n",
    "    \"Luxembourg\",\"Malta\",\"Netherlands\",\"Poland\",\"Portugal\",\"Romania\",\n",
    "    \"Slovakia\",\"Slovenia\",\"Spain\",\"Sweden\"\n",
    "]\n",
    "\n",
    "# Name normalizations\n",
    "rename_map = {\n",
    "    \"USA\":                              \"United States\",\n",
    "    \"Russian Federation\":               \"Russia\",\n",
    "    \"United Rep. of Tanzania\":          \"Tanzania\",\n",
    "    \"Rep. of Korea\":                    \"South Korea\",\n",
    "    \"China, Hong Kong SAR\":             \"Hong Kong\",\n",
    "    \"China, Macao SAR\":                 \"Macau\",\n",
    "    \"Bolivia (Plurinational State of)\": \"Bolivia\",\n",
    "    \"Viet Nam\":                         \"Vietnam\",\n",
    "    \"Brunei Darussalam\":                \"Brunei\",\n",
    "    \"Lao People's Dem. Rep.\":           \"Laos\",\n",
    "    \"Dem. People's Rep. of Korea\":      \"North Korea\",\n",
    "    \"Dem. Rep. of the Congo\":           \"DR Congo\",\n",
    "    \"Côte d'Ivoire\":                    \"Ivory Coast\",\n",
    "    \"Bosnia Herzegovina\":               \"Bosnia and Herzegovina\",\n",
    "    \"Rep. of Moldova\":                  \"Moldova\",\n",
    "    \"Dominican Rep.\":                   \"Dominican Republic\",\n",
    "    \"Cayman Isds\":                      \"Cayman Islands\",\n",
    "    \"Faroe Isds\":                       \"Faroe Islands\",\n",
    "    \"Solomon Isds\":                     \"Solomon Islands\",\n",
    "    \"Cabo Verde\":                       \"Cape Verde\",\n",
    "    \"Timor-Leste\":                      \"East Timor\",\n",
    "    \"State of Palestine\":               \"Palestine\",\n",
    "    \"Central African Rep.\":             \"Central African Republic\",\n",
    "    \"Saint Kitts and Nevis\":            \"St. Kitts and Nevis\",\n",
    "    \"Saint Vincent and the Grenadines\": \"St. Vincent and the Grenadines\",\n",
    "    \"Saint Lucia\":                      \"St. Lucia\"\n",
    "}\n",
    "\n",
    "rename_tariffs = {\n",
    "    \"Korea, Rep.\":                 \"South Korea\",\n",
    "    \"Slovak Republic\":             \"Slovakia\",\n",
    "    \"Czech Republic\":              \"Czechia\",\n",
    "    \"Russian Federation\":          \"Russia\",\n",
    "    \"Congo, Dem. Rep.\":            \"DR Congo\",\n",
    "    \"Congo, Rep.\":                 \"Congo\",\n",
    "    \"Iran, Islamic Rep.\":          \"Iran\",\n",
    "    \"Lao PDR\":                     \"Laos\",\n",
    "    \"Kyrgyz Republic\":             \"Kyrgyzstan\",\n",
    "    \"Cote d'Ivoire\":               \"Ivory Coast\",\n",
    "    \"Hong Kong, China\":            \"Hong Kong\",\n",
    "    \"Macao\":                       \"Macau\",\n",
    "    \"Egypt, Arab Rep.\":            \"Egypt\",\n",
    "    \"Bahamas, The\":                \"Bahamas\",\n",
    "    \"Gambia, The\":                 \"Gambia\",\n",
    "    \"Serbia, FR(Serbia/Montenegro)\": \"Serbia\",\n",
    "    \"Syrian Arab Republic\":        \"Syria\",\n",
    "    \"Ethiopia(excludes Eritrea)\":  \"Ethiopia\",\n",
    "    \"Turkey\":                      \"Türkiye\",\n",
    "    \"Korea, Dem. Rep.\":            \"North Korea\"\n",
    "}\n",
    "\n",
    "rename_tc = {\n",
    "    \"Myanmar (Burma)\":          \"Myanmar\",\n",
    "    \"Bosnia & Herzegovina\":     \"Bosnia and Herzegovina\",\n",
    "    \"Trinidad & Tobago\":        \"Trinidad and Tobago\",\n",
    "    \"Congo - Kinshasa\":         \"DR Congo\",\n",
    "    \"Congo - Brazzaville\":      \"Congo\",\n",
    "    \"Turkey\":                   \"Türkiye\",\n",
    "    \"Timor-Leste\":              \"East Timor\",\n",
    "    \"St. Vincent & Grenadines\": \"St. Vincent and the Grenadines\",\n",
    "    \"St. Kitts & Nevis\":        \"St. Kitts and Nevis\",\n",
    "    \"Hong Kong SAR China\":      \"Hong Kong\",\n",
    "    \"Antigua & Barbuda\":        \"Antigua and Barbuda\"\n",
    "}\n",
    "\n",
    "def normalize_with_map(series: pd.Series, mapping: dict) -> pd.Series:\n",
    "  \"\"\"\n",
    "  Mimics the R normalize_with_map: only replace when key is in mapping.\n",
    "  \"\"\"\n",
    "  return series.replace(mapping)\n",
    "\n",
    "#---------------------------------------\n",
    "# Load transport costs once & normalize\n",
    "#---------------------------------------\n",
    "tc_feather_path = os.path.join(path_oecd_tc, \"transport_costs.feather\")\n",
    "\n",
    "tc_table = feather.read_table(tc_feather_path)\n",
    "tc = tc_table.to_pandas()\n",
    "\n",
    "# Match your R code logic\n",
    "tc = tc.rename(columns={\"hs\": \"hs4\"})\n",
    "tc[\"exporter\"] = normalize_with_map(tc[\"exporter\"], rename_tc)\n",
    "tc[\"importer\"] = normalize_with_map(tc[\"importer\"], rename_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd66b868-4b3a-425a-9125-e8c18f9f9182",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index must either be string or integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yy \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# 1) Flows for year yy\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     flows_y \u001b[38;5;241m=\u001b[39m feather\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m      9\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_comtrade, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbulktrade_hs6_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.feather\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     flows_y \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 13\u001b[0m         flows_y[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexporter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimporter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhs6\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhs6_desc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprimary_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkg\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Convert year to numeric\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     flows_y[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(flows_y[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pyarrow/table.pxi:1693\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular.__getitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pyarrow/table.pxi:1779\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular.column\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pyarrow/table.pxi:1725\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular._ensure_integer_index\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index must either be string or integer"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# MAIN LOOP — Creates flows_final_{year}\n",
    "#---------------------------------------\n",
    "flows_final_by_year = {}  # dict instead of globals\n",
    "\n",
    "for yy in years:\n",
    "    # 1) Flows for year yy\n",
    "    flows_y = feather.read_table(\n",
    "        os.path.join(path_comtrade, f\"bulktrade_hs6_{yy}.feather\")\n",
    "    )\n",
    "\n",
    "    flows_y = (\n",
    "        flows_y[[\"exporter\", \"importer\", \"period\", \"hs6\", \"hs6_desc\",\n",
    "                 \"primary_value\", \"kg\"]]\n",
    "        .rename(columns={\"period\": \"year\"})\n",
    "    )\n",
    "\n",
    "    # Convert year to numeric\n",
    "    flows_y[\"year\"] = pd.to_numeric(flows_y[\"year\"], errors=\"coerce\")\n",
    "\n",
    "    # Filter\n",
    "    flows_y = flows_y[\n",
    "        (~flows_y[\"exporter\"].isin(toosmall_territories)) &\n",
    "        (~flows_y[\"importer\"].isin(toosmall_territories)) &\n",
    "        (flows_y[\"kg\"].notna()) &\n",
    "        (flows_y[\"kg\"] > 0) &\n",
    "        (flows_y[\"primary_value\"].notna())\n",
    "    ]\n",
    "\n",
    "    # Normalize country names\n",
    "    flows_y[\"exporter\"] = normalize_with_map(flows_y[\"exporter\"], rename_map)\n",
    "    flows_y[\"importer\"] = normalize_with_map(flows_y[\"importer\"], rename_map)\n",
    "\n",
    "    # 2) Tariffs for year yy\n",
    "    tariffs_y = feather.read_table(\n",
    "        os.path.join(path_wits, f\"tariffs_hs6_{yy}.feather\")\n",
    "    )\n",
    "    tariffs_y = tariffs_y[[\"exporter\", \"importer\", \"year\", \"hs\", \"tau\"]]\n",
    "\n",
    "    tariffs_y[\"exporter\"] = normalize_with_map(tariffs_y[\"exporter\"], rename_tariffs)\n",
    "    tariffs_y[\"importer\"] = normalize_with_map(tariffs_y[\"importer\"], rename_tariffs)\n",
    "\n",
    "    # EU zero-tariffs logic\n",
    "    # EU-EU -> 0\n",
    "    mask_eu_eu = tariffs_y[\"exporter\"].isin(eu_countries) & tariffs_y[\"importer\"].isin(eu_countries)\n",
    "    tariffs_y.loc[mask_eu_eu, \"tau\"] = 0\n",
    "\n",
    "    # UK-EU pre-2021 -> 0\n",
    "    mask_uk_eu = (\n",
    "        ((tariffs_y[\"exporter\"] == \"United Kingdom\") & tariffs_y[\"importer\"].isin(eu_countries)) |\n",
    "        ((tariffs_y[\"importer\"] == \"United Kingdom\") & tariffs_y[\"exporter\"].isin(eu_countries))\n",
    "    ) & (tariffs_y[\"year\"] < 2021)\n",
    "    tariffs_y.loc[mask_uk_eu, \"tau\"] = 0\n",
    "\n",
    "    # EU pooling for missing importer-EU tariffs\n",
    "    eu_pool_y = (\n",
    "        tariffs_y[tariffs_y[\"importer\"].isin(eu_countries)]\n",
    "        .groupby([\"exporter\", \"year\", \"hs\"], as_index=False)\n",
    "        .agg(tau_eu=(\"tau\", \"mean\"))\n",
    "    )\n",
    "    # merge & use tau_eu to fill missing tau when importer is EU\n",
    "    tariffs_y = tariffs_y.merge(eu_pool_y, on=[\"exporter\", \"year\", \"hs\"], how=\"left\")\n",
    "    mask_eu_missing = tariffs_y[\"importer\"].isin(eu_countries) & tariffs_y[\"tau\"].isna()\n",
    "    tariffs_y.loc[mask_eu_missing, \"tau\"] = tariffs_y.loc[mask_eu_missing, \"tau_eu\"]\n",
    "    tariffs_y = tariffs_y.drop(columns=[\"tau_eu\"])\n",
    "\n",
    "    # distinct(importer, exporter, year, hs, .keep_all = TRUE)\n",
    "    tariffs_y = tariffs_y.drop_duplicates(\n",
    "        subset=[\"importer\", \"exporter\", \"year\", \"hs\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    # 3) Merge flows + tariffs + transport costs (year yy only)\n",
    "    flows3_y = flows_y.merge(\n",
    "        tariffs_y,\n",
    "        left_on=[\"exporter\", \"importer\", \"year\", \"hs6\"],\n",
    "        right_on=[\"exporter\", \"importer\", \"year\", \"hs\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    flows3_y[\"hs4\"] = flows3_y[\"hs6\"].str[:4]\n",
    "\n",
    "    # merge with transport costs for that year\n",
    "    tc_yy = tc[tc[\"year\"] == yy]\n",
    "    flows_final_y = flows3_y.merge(\n",
    "        tc_yy,\n",
    "        on=[\"importer\", \"exporter\", \"year\", \"hs4\"],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_tc\")\n",
    "    ).drop(columns=[\"hs4\", \"hs\"])\n",
    "\n",
    "    flows_final_by_year[yy] = flows_final_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f6735-0958-455b-b035-44c4b020f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# Bind all years\n",
    "#---------------------------------------\n",
    "final_all = pd.concat(flows_final_by_year.values(), ignore_index=True)\n",
    "\n",
    "# Keep only rows with non-missing freight\n",
    "final_all = final_all[final_all[\"freight\"].notna()].copy()\n",
    "\n",
    "# freight as proportion initially\n",
    "final_all[\"freight\"] = final_all[\"freight\"] / 100.0\n",
    "\n",
    "# fob for most importers\n",
    "mask_non_special = ~final_all[\"importer\"].isin([\"Canada\", \"Bermuda\", \"South Africa\"])\n",
    "final_all[\"fob\"] = final_all[\"primary_value\"]\n",
    "final_all.loc[mask_non_special, \"fob\"] = (\n",
    "    final_all.loc[mask_non_special, \"primary_value\"]\n",
    "    - final_all.loc[mask_non_special, \"primary_value\"] * final_all.loc[mask_non_special, \"freight\"]\n",
    ")\n",
    "\n",
    "# For Canada, Bermuda, South Africa: reconstruct cost then freight\n",
    "final_all[\"cost\"] = final_all[\"primary_value\"]\n",
    "mask_special = final_all[\"importer\"].isin([\"Canada\", \"Bermuda\", \"South Africa\"])\n",
    "final_all.loc[mask_special, \"cost\"] = (\n",
    "    final_all.loc[mask_special, \"primary_value\"]\n",
    "    / (1 - final_all.loc[mask_special, \"freight\"])\n",
    ")\n",
    "final_all[\"freight\"] = final_all[\"cost\"] - final_all[\"fob\"]\n",
    "\n",
    "# Drop cost and primary_value\n",
    "final_all = final_all.drop(columns=[\"cost\", \"primary_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed967f4-d789-43f6-9732-2ed7ef1f1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# Add all the exp/imp totals via groupby + transform\n",
    "#---------------------------------------\n",
    "# exporter, year, hs6\n",
    "final_all[\"exp_prodvalue_toworld\"] = (\n",
    "    final_all.groupby([\"exporter\", \"year\", \"hs6\"])[\"fob\"].transform(\"sum\")\n",
    ")\n",
    "final_all[\"exp_prodkg_toworld\"] = (\n",
    "    final_all.groupby([\"exporter\", \"year\", \"hs6\"])[\"kg\"].transform(\"sum\")\n",
    ")\n",
    "\n",
    "# importer, year, hs6\n",
    "final_all[\"imp_prodvalue_fromworld\"] = (\n",
    "    final_all.groupby([\"importer\", \"year\", \"hs6\"])[\"fob\"].transform(\"sum\")\n",
    ")\n",
    "final_all[\"imp_prodkg_fromworld\"] = (\n",
    "    final_all.groupby([\"importer\", \"year\", \"hs6\"])[\"kg\"].transform(\"sum\")\n",
    ")\n",
    "\n",
    "# exporter, year\n",
    "final_all[\"exp_totalvalue_toworld\"] = (\n",
    "    final_all.groupby([\"exporter\", \"year\"])[\"fob\"].transform(\"sum\")\n",
    ")\n",
    "final_all[\"exp_totalkg_toworld\"] = (\n",
    "    final_all.groupby([\"exporter\", \"year\"])[\"kg\"].transform(\"sum\")\n",
    ")\n",
    "\n",
    "# importer, year\n",
    "final_all[\"imp_totalvalue_fromworld\"] = (\n",
    "    final_all.groupby([\"importer\", \"year\"])[\"fob\"].transform(\"sum\")\n",
    ")\n",
    "final_all[\"imp_totalkg_fromworld\"] = (\n",
    "    final_all.groupby([\"importer\", \"year\"])[\"kg\"].transform(\"sum\")\n",
    ")\n",
    "\n",
    "# exporter, importer, year\n",
    "final_all[\"exp_totalvalue_toimp\"] = (\n",
    "    final_all.groupby([\"exporter\", \"importer\", \"year\"])[\"fob\"].transform(\"sum\")\n",
    ")\n",
    "final_all[\"exp_totalkg_toimp\"] = (\n",
    "    final_all.groupby([\"exporter\", \"importer\", \"year\"])[\"kg\"].transform(\"sum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d5024-f546-4394-aae0-09b05860cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# Fill tau over time (down then up) by exporter-importer-hs6\n",
    "#---------------------------------------\n",
    "final_all = final_all.sort_values([\"exporter\", \"importer\", \"hs6\", \"year\"])\n",
    "\n",
    "group_keys = [\"exporter\", \"importer\", \"hs6\"]\n",
    "\n",
    "# Pass 1: down (ffill)\n",
    "final_all[\"tau_down_work\"] = (\n",
    "    final_all.groupby(group_keys)[\"tau\"].ffill()\n",
    ")\n",
    "final_all[\"tau_after_down\"] = np.where(\n",
    "    final_all[\"tau\"].isna(), final_all[\"tau_down_work\"], final_all[\"tau\"]\n",
    ")\n",
    "\n",
    "# Pass 2: up (bfill where still missing)\n",
    "final_all[\"tau_up_work\"] = (\n",
    "    final_all.groupby(group_keys)[\"tau_after_down\"].bfill()\n",
    ")\n",
    "final_all[\"tau_final\"] = np.where(\n",
    "    final_all[\"tau_after_down\"].isna(),\n",
    "    final_all[\"tau_up_work\"],\n",
    "    final_all[\"tau_after_down\"]\n",
    ")\n",
    "\n",
    "# Replace tau, drop helpers\n",
    "final_all[\"tau\"] = final_all[\"tau_final\"]\n",
    "final_all = final_all.drop(columns=[\"tau_down_work\", \"tau_up_work\", \"tau_after_down\", \"tau_final\"])\n",
    "\n",
    "# tau: missing -> 0, then scale /100 to get ad valorem\n",
    "final_all[\"tau\"] = final_all[\"tau\"].fillna(0.0)\n",
    "final_all[\"tau\"] = final_all[\"tau\"] / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c72c5-4ec5-448d-9c06-7e87f8a651f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# Keep relevant columns & order (mirrors your select())\n",
    "#---------------------------------------\n",
    "desired_cols = [\n",
    "    \"exporter\", \"importer\", \"year\", \"hs6\", \"hs6_desc\",\n",
    "    # R did some reordering using positions; here we explicitly choose\n",
    "    \"kg\", \"tau\", \"freight\", \"fob\",\n",
    "    \"exp_prodvalue_toworld\", \"exp_prodkg_toworld\",\n",
    "    \"imp_prodvalue_fromworld\", \"imp_prodkg_fromworld\",\n",
    "    \"exp_totalvalue_toworld\", \"exp_totalkg_toworld\",\n",
    "    \"imp_totalvalue_fromworld\", \"imp_totalkg_fromworld\",\n",
    "    \"exp_totalvalue_toimp\", \"exp_totalkg_toimp\"\n",
    "]\n",
    "\n",
    "# keep only those that actually exist (just in case tc had extra cols)\n",
    "existing_desired_cols = [c for c in desired_cols if c in final_all.columns]\n",
    "final_all2 = final_all[existing_desired_cols].copy()\n",
    "\n",
    "#---------------------------------------\n",
    "# Split back into flows_final_{year} and write parquet\n",
    "#---------------------------------------\n",
    "for yy in years:\n",
    "    flows_final_y = final_all2[final_all2[\"year\"] == yy].copy()\n",
    "    flows_final_by_year[yy] = flows_final_y  # store in dict if needed\n",
    "\n",
    "    out_path = os.path.join(path_out, f\"allflows_forCCAs_{yy}.parquet\")\n",
    "    flows_final_y.to_parquet(out_path, index=False)\n",
    "    print(f\"Wrote {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
